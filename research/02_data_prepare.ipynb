{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Omar\\\\Desktop\\\\Omar_Files\\\\Python_Analysis\\\\EndToEndMachineLearningProjectAutoMobilePrice\\\\research'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Omar\\\\Desktop\\\\Omar_Files\\\\Python_Analysis\\\\EndToEndMachineLearningProjectAutoMobilePrice'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path:Path\n",
    "    #updated_base_model_path:Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.AutoMobilePriceRegression.constants import *\n",
    "from src.AutoMobilePriceRegression.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config.prepare_base_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            #updated_base_model_path=Path(config.updated_base_model_path),\n",
    "            train_data_path= config.train_data_path,\n",
    "            test_data_path=config.test_data_path        \n",
    "            \n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,OneHotEncoder\n",
    "from src.AutoMobilePriceRegression import logger\n",
    "from src.AutoMobilePriceRegression.utils.common import get_size\n",
    "#from src.AutoMobilePriceRegression.components.data_ingestion import DataIngestion\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self,config:PrepareBaseModelConfig):\n",
    "        self.config= config\n",
    "    \n",
    "\n",
    "    def get_data_transformer_object(self):\n",
    "        numerical_columns = ['length', 'width', 'height', 'curb_weight', 'engine_size','peak_rpm', 'city_mpg', 'highway_mpg']\n",
    "        categorical_columns = ['num_of_doors', 'body_style', 'drive_wheels','engine_location','num_of_cylinders', 'fuel_system']\n",
    "\n",
    "        num_pipeline= Pipeline(steps=[\n",
    "            (\"scaler\",StandardScaler())\n",
    "            ])\n",
    "        \n",
    "        cat_pipeline=Pipeline(steps=[\n",
    "            (\"OneHotEncoder\",OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "            (\"scaler\",StandardScaler(with_mean=False))\n",
    "            ])\n",
    "\n",
    "        preprocessor=ColumnTransformer([\n",
    "            (\"num_pipeline\",num_pipeline,numerical_columns),\n",
    "            (\"cat_pipelines\",cat_pipeline,categorical_columns)\n",
    "            ])  \n",
    "        \n",
    "        return preprocessor\n",
    "    \n",
    "    def initiate_data_transformation(self): \n",
    "        train_df=pd.read_csv(r\"./artifacts/data_ingestion/train_data.csv\")\n",
    "        test_df=pd.read_csv(r\"./artifacts/data_ingestion/test_data.csv\")\n",
    "\n",
    "        logger.info(\"Read train and test data completed\")\n",
    "\n",
    "        preprocessing_obj=self.get_data_transformer_object()        \n",
    "\n",
    "        target_column_name=\"price\"        \n",
    "\n",
    "        input_feature_train_df=train_df.drop(columns=[target_column_name],axis=1)\n",
    "        target_feature_train_df=train_df[target_column_name]\n",
    "\n",
    "        input_feature_test_df=test_df.drop(columns=[target_column_name],axis=1)\n",
    "        target_feature_test_df=test_df[target_column_name]     \n",
    "\n",
    "        input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "        input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "        train_arr = np.c_[\n",
    "                input_feature_train_arr, np.array(target_feature_train_df)\n",
    "                ]\n",
    "        test_arr = np.c_[\n",
    "                 input_feature_test_arr, np.array(target_feature_test_df)\n",
    "                 ]\n",
    "        \n",
    "        if not os.path.exists(self.config.train_data_path):\n",
    "                train_arr = pd.DataFrame(train_arr)#columns=[colnames])\n",
    "                train_arr.to_csv(self.config.train_data_path,index=False)\n",
    "        if not os.path.exists(self.config.test_data_path):\n",
    "                test_arr = pd.DataFrame(test_arr)#,columns=[colnames])\n",
    "                test_arr.to_csv(self.config.test_data_path,index=False)        \n",
    "\n",
    "        return(\n",
    "                self.config.train_data_path,\n",
    "                self.config.test_data_path\n",
    "         \n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-05 17:50:01,376: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-07-05 17:50:01,382: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-07-05 17:50:01,384: INFO: common: created directory at: artifacts]\n",
      "[2024-07-05 17:50:01,387: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "[2024-07-05 17:50:01,436: INFO: 357159626: Read train and test data completed]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(prepare_base_model_config)\n",
    "    prepare_base_model.get_data_transformer_object()\n",
    "    prepare_base_model.initiate_data_transformation()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
